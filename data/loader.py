import numpy as np
import pandas as pd

from config import DATA_CONFIG


def load_data():
    df = pd.read_csv(DATA_CONFIG.DATA_PATH, sep='\t', names=DATA_CONFIG.DATA_COLUMNS)

    print(f"æ•°æ®é›†åŠ è½½å®Œæˆ: {len(df)}æ¡è¯„åˆ†è®°å½•")
    print(f"ç”¨æˆ·æ•°é‡: {df['user_id'].nunique()}, ç”µå½±æ•°é‡: {df['item_id'].nunique()}")

    return df

def build_rating_matrix(df):
    n_users = df['user_id'].nunique()
    n_items = df['item_id'].nunique()

    # åˆ›å»ºä»åŸå§‹IDåˆ°çŸ©é˜µç´¢å¼•çš„æ˜ å°„
    user_mapping = {user: idx for idx, user in enumerate(df['user_id'].unique())}
    item_mapping = {item: idx for idx, item in enumerate(df['item_id'].unique())}

    # æ„å»ºè¯„åˆ†çŸ©é˜µ
    R = np.zeros((n_users, n_items))
    for _, row in df.iterrows():
        user_idx = user_mapping[row['user_id']]
        item_idx = item_mapping[row['item_id']]
        R[user_idx, item_idx] = row['rating']

    sparsity = 100 * (1 - np.count_nonzero(R) / (n_users * n_items))

    print(f"è¯„åˆ†çŸ©é˜µæ„å»ºå®Œæˆ | ç»´åº¦: {R.shape} | ç¨€ç–åº¦: {sparsity:.2f}%")

    return R, user_mapping, item_mapping


def load_movie_attributes():
    import pandas as pd
    import numpy as np
    from config import DATA_CONFIG

    # è¯»å– MovieLens u.item æ•°æ®
    movies = pd.read_csv(
        DATA_CONFIG.ITEM_PATH,
        sep="|",
        encoding="latin-1",
        header=None,
        names=DATA_CONFIG.ITEM_COLUMNS
    )

    # ===================== ç±»å‹å±æ€§ï¼ˆone-hot, å…±19ç»´ï¼‰ =====================
    genre_attrs = movies.iloc[:, 5:].astype(np.float32).values  # shape = (1682, 19)

    # ===================== å¹´ä»½ scalar å±æ€§ï¼ˆå½’ä¸€åŒ–ï¼‰ =====================
    release_years = []
    for date_str in movies["release_date"]:
        if pd.isna(date_str):
            year = 1900
        else:
            try:
                year = int(date_str.strip()[-4:])
            except:
                year = 1900
        release_years.append(year)

    years = np.array(release_years)
    min_year = years.min()
    max_year = years.max()

    year_scalars = ((years - min_year) / (max_year - min_year)).astype(np.float32)  # å½’ä¸€åŒ–åˆ° [0, 1]
    year_scalars = year_scalars.reshape(-1, 1)  # shape = (1682, 1)

    # ===================== åˆå¹¶å±æ€§ï¼šç±»å‹ + å¹´ä»½ =====================
    full_attrs = np.concatenate([genre_attrs, year_scalars], axis=1)  # shape = (1682, 20)

    # ===================== æ„é€  item_id â†’ å±æ€§æ˜ å°„ =====================
    attr_dict = {}
    for idx, row in movies.iterrows():
        item_id = int(row["movie_id"])
        attr_dict[item_id] = full_attrs[idx]

    num_attrs = full_attrs.shape[1]
    print(f"[INFO] ğŸ¬ ç”µå½±å±æ€§åŠ è½½å®Œæˆ | ç±»å‹å±æ€§: {genre_attrs.shape[1]} | å¹´ä»½: scalar â†’ æ€»ç»´åº¦: {num_attrs}")
    print(f"[INFO] ğŸ“† å¹´ä»½å½’ä¸€åŒ–èŒƒå›´: [{min_year}, {max_year}] â†’ [0.0, 1.0]")

    return attr_dict, num_attrs

def load_movie_attributes():
    # è¯»å–å¸¦å¯¼æ¼”å’Œæ¼”å‘˜çš„æ–°æ–‡ä»¶
    movies = pd.read_csv(
        DATA_CONFIG.ITEM_WITH_DIRECTOR_AND_ACTOR_PATH,
        sep="|",
        encoding="latin-1",
        header=None
    )

    column_names = DATA_CONFIG.ITEM_COLUMNS + ['director', 'actors']
    movies.columns = column_names

    # ================== ç±»å‹å±æ€§ï¼ˆone-hot, 19ç»´ï¼‰ ==================
    genre_attrs = movies.iloc[:, 5:24].astype(np.float32).values

    # ================== å¹´ä»½å±æ€§ scalar ==================
    release_years = []
    for date_str in movies["release_date"]:
        if pd.isna(date_str):
            year = 1900
        else:
            try:
                year = int(date_str.strip()[-4:])
            except:
                year = 1900
        release_years.append(year)

    years = np.array(release_years)
    min_year, max_year = years.min(), years.max()
    year_scalars = ((years - min_year) / (max_year - min_year)).astype(np.float32).reshape(-1, 1)

    # ================== å¯¼æ¼” multi-hot ç¼–ç  ==================
    all_director_set = set()
    director_lists = []

    for d_str in movies["director"].fillna("Unknown"):
        directors = [d.strip() for d in str(d_str).split(",") if d.strip()]
        director_lists.append(directors)
        all_director_set.update(directors)

    unique_directors = sorted(all_director_set)
    director2idx = {d: i for i, d in enumerate(unique_directors)}
    director_multi_hot = np.zeros((len(movies), len(director2idx)), dtype=np.float32)
    for idx, directors in enumerate(director_lists):
        for d in directors:
            if d in director2idx:
                director_multi_hot[idx, director2idx[d]] = 1.0

    # ================== æ¼”å‘˜ multi-hot ç¼–ç ï¼ˆå–å…¨éƒ¨ï¼‰ ==================
    all_actor_set = set()
    actor_lists = []

    for actor_str in movies['actors'].fillna('Unknown'):
        actors = [a.strip() for a in str(actor_str).split(',') if a.strip()]
        actor_lists.append(actors)
        all_actor_set.update(actors)

    unique_actors = sorted(all_actor_set)
    actor2idx = {a: i for i, a in enumerate(unique_actors)}
    actor_multi_hot = np.zeros((len(movies), len(actor2idx)), dtype=np.float32)
    for idx, actors in enumerate(actor_lists):
        for a in actors:
            if a in actor2idx:
                actor_multi_hot[idx, actor2idx[a]] = 1.0

    # ================== åˆå¹¶æ‰€æœ‰å±æ€§ ==================
    full_attrs = np.concatenate([genre_attrs, year_scalars, director_multi_hot, actor_multi_hot], axis=1)

    print(f"[INFO] ğŸ¬ å±æ€§ç»´åº¦ç»Ÿè®¡:")
    print(f" - ç±»å‹ç»´åº¦: {genre_attrs.shape[1]}")
    print(f" - å¹´ä»½ç»´åº¦: {year_scalars.shape[1]}")
    print(f" - å¯¼æ¼”ç»´åº¦: {director_multi_hot.shape[1]}")
    print(f" - æ¼”å‘˜ç»´åº¦: {actor_multi_hot.shape[1]}")
    print(f" - åˆå¹¶åç»´åº¦: {full_attrs.shape[1]}")

    # æ„é€  item_id â†’ å±æ€§å‘é‡
    attr_dict = {}
    for idx, row in movies.iterrows():
        item_id = int(row["movie_id"])
        attr_dict[item_id] = full_attrs[idx]

    return attr_dict, full_attrs.shape[1]
